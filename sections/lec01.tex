\pagebreak

\section{Introduction to Information Theory}

Information theory is the study of communication over channels.
What is a channel?  Some examples of a channel are:
\begin{frml}
	Voice &\rightarrow Ears \\
	Eye &\rightarrow Brain \\
	DNA &\rightarrow DNA \\
	Antenna\;\; on\;\; Earth &\rightarrow Mars \;Rover \\
	Phone &\rightarrow Another Phone \\
\end{frml}
where the \textit{medium} of the channel is some physical system that the communication
is being transmitted over, e.g. in the case of Voice $\rightarrow $ 
Ears the medium is \textit{air}.

\begin{defn}{Fundamental Problem in Information Theory}{}
The \textbf{fundamental problem} in information theory is reliable communication 
over an unreliable channel.

\medskip
An \textbf{unreliable channel} is one where the \textit{received signal} is not equal
to the \textit{transmitted signal}, i.e.
\begin{frml}
	\text{Received Signal} \approx \text{Transmitted Signal} + \text{Noise}
\end{frml}
\end{defn}

There are two predominant soltuions that address this problem of unreliable channels.
The first option is a \textit{physical solution}, which attempts to address the physical
limitations of the medium to reduce the noise. Alternatively, there are \textit{system
solutions}, which accept the physical limitations of the channel, and attempt to
transform the overall system into a reliable one using \textit{encodings and decodings}.

Information theory is all about \textit{system solutions}. System solutions 
take the form of the pipeline below:

\begin{figure}[h!]
	\centering
\begin{tikzpicture}
[
encdecnode/.style={rectangle, draw=green!60, fill=green!5, very thick, minimum size=10mm, inner sep=10},
channelnode/.style={rectangle, draw=red!60, fill=red!5, very thick, minimum size=10mm, inner sep=10},
every node/.style={outer sep=7}
]
%Nodes
\node[]		(1) {$s$ };
\node[]		(1t) [below=.0cm of 1] {Source Message};
\node[encdecnode]        (2)       [right=of 1] {Encoder};
\node[]		(2t) [below=.7cm of 2] {Adds Redundancy};
\node[]        (3)       [right=of 2] {$t$};
\node[]		(3t) [below=.1cm of 3] {Coded Transmission};
\node[channelnode]        (4)       [right=of 3] {Channel};
\node[]		(4t) [below=.7cm of 4] {Adds Noise $n$};
\node[]        (5)       [right=of 4] {$r$};
\node[]		(5t) [below=.1cm of 5] {Received Transmission};
\node[encdecnode]        (6)       [right=of 5] {Decoder};
\node[]		(6t) [below=.7cm of 6] {Try to Infer $s$ and $n$};
\node[]        (7)       [right=of 6] {$\hat{s}$};
\node[]		(7t) [below=.1cm of 7] {Decoded message};

%Lines
\draw[->] (1.east) -- (2.west);
\draw[->] (2.east) -- (3.west);
\draw[->] (2t.north) -- (2.south);
\draw[->] (3.east) -- (4.west);
\draw[->] (4.east) -- (5.west);
\draw[->] (4t.north) -- (4.south);
\draw[->] (5.east) -- (6.west);
\draw[->] (6.east) -- (7.west);
\draw[->] (6t.north) -- (6.south);
%\draw[->] (uppercircle.south) -- (maintopic.north);
%\draw[->] (maintopic.east) -- (rightsquare.west);
%\draw[->] (rightsquare.south) .. controls +(down:7mm) and +(right:7mm) .. (lowercircle.east);
\end{tikzpicture}
\end{figure}

In this framework, the \textit{Encoder} and \textit{Decoder} are the focus of
system solutions.

To examine this in more detail, let's imagine an imaginary, toy, channel.
This channel is called the \textit{Binary Symmetric Channel}.

\begin{defn}{Binary Symmetric Channel}{}
	A \textbf{Binary Symmetric Channel}, with input $x$ and output $y$, follows
	the distribution
	\begin{frml}
		&P(y = 0 | x = 0) = 1 - f \\
		&P(y = 0 | x = 1) = f \\
		&P(y = 1 | x = 1) = 1 - f \\
		&P(y = 1 | x = 0) = f \\
	\end{frml}
i.e. with probability $f$, a bit of the input $x$ will be flipped. A diagram of
this channel might look like:
	\medskip
	\begin{center}
\begin{tikzpicture}
	\node[] (in) at (0,1) {Input $x$};
	\node[] (on) at (4,1) {Output $y$};
	\node[] (fn) at (2.1,1.3) {$f$};
	\node[] (tl) at (1,2) {0};
	\node[] (bl) [below=of tl] {1};
	\node[] (tr) [right=of tl] {0};
	\node[] (br) [right=of bl] {1};

	\path[->] (tl) edge node[midway, above] {$1 - f$} (tr);
	\path[->] (bl) edge node[midway, below] {$1 - f$} (br);
	\path[->] (tl) edge node[sloped, below] {} (br);
	\path[->] (bl) edge node[sloped, above] {} (tr);
\end{tikzpicture}
\end{center}
\end{defn}

Suppose we have a disk drive which follows the behavior of a binary
symmetric channel with $f = 0.1$. If a file of $N=10,000$ bits is stored
and then read from this disk drive, roughly how many bits will be flipped?
\begin{frml}
	1000 \pm 30
\end{frml}
Why? Note that this follows a binomial distribution. Binomial distributions have
mean $Np$ and variance $Npq$, where in this problem $p = f$ and $q = 1 - f$.
This is \textit{not a good disk drive}. We're flipping far too many bits, here.

We can instead ask the question: How small does $f$ need to be in order to have
a disk drive that is sell-able. Imagine that 1GB of data is written every day,
for 5 years. This results in the number of bits being sent through this
channel to be
\begin{frml}
	\text{\# of bits passed} = 5 \times 365 \times 8 \times 10^9 \approx 10^{13}
\end{frml}
In order to guarantee a 1\% chance that a any file has a single bit flipped in
5 years, then we need $f\approx10^{-15}$.
The mean and standard deviation of the number of bits flipped is modeled by
the distribution:
\begin{frml}
	\text{Mean: }&Np = 10^{13}\times10^{-15} = 10^{-2} = 0.01 \\
	\text{Std: }&\sqrt{Npq} =  \sqrt{10^{13}\times10^{-15}\times(1 - 10^{-15})} \approx 0.1
\end{frml}
Thus, with $f = 10^{-15}$ the number of bits that will flip in 5 years of use is
$0.01 \pm 0.1$
